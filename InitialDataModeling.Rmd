---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

```{r dataframes loading}

setwd("/Users/annabelle/Documents/school/HonoursYear/HonoursProject/HonoursProjectCode")
list.files()

#load the csv as df
BCDf2 <- read.csv(file = "BCDf.csv", header=TRUE, sep=",")
AlzDf2 <- read.csv(file = "AlzDf.csv", header = TRUE, sep=",")
CCDf2 <- read.csv(file = "CCDf.csv", header = TRUE, sep = ",")
AuSDf2 <- read.csv(file = "AuSDf.csv", header = TRUE, sep= ",")
DiabetesDf2 <- read.csv(file = "DiabetesDf.csv", header = TRUE, sep = ",")
LiverDf2 <- read.csv(file = "LiverDf.csv", header = TRUE, sep = ",")
FertDf2 <- read.csv(file = "FertDf.csv", header = TRUE, sep = ",")
HAPDf2 <- read.csv(file = "HAPDf.csv", header = TRUE, sep = ",")
LBPDf2 <- read.csv(file = "LBPDf.csv", header = TRUE, sep = ",")


```
```{r check the data}
summary(BCDf2)
summary(AlzDf2)
summary(CCDf2)
summary(AuSDf2)
summary(DiabetesDf2)
summary(LiverDf2)
summary(FertDf2)
summary(HAPDf2)
summary(LBPDf2)
```

```{r Training and testing sets}

# use caret
library(caret)
#BCDf
#drop column X
BCDf2<-subset(BCDf2,select=c(- X, -X.1))
colnames(BCDf2)
#shuffle the data
BCDf_shuff <- BCDf2[sample(nrow(BCDf2)),]
#split the BCDf data
inTrain <- createDataPartition(y = BCDf_shuff$diagnosis, p=0.75, list = FALSE)
BCDf_train <- BCDf_shuff[inTrain, ]
BCDf_test <- BCDf_shuff[-inTrain, ]
dim(BCDf_train)
dim(BCDf_test)

#AlzDf
#drop column X
AlzDf2 <-subset(AlzDf2, select=c(-X, -Subject.ID, -MRI.ID))
AlzDf_shuff <-AlzDf2[sample(nrow(AlzDf2)),]
dim(AlzDf_shuff)
inTrainAlz <- createDataPartition(y= AlzDf_shuff$Group, p = 0.75, list = FALSE)
AlzDf_train <- AlzDf_shuff[inTrainAlz,]
AlzDf_test <- AlzDf_shuff[-inTrainAlz,]
dim(AlzDf_train)
dim(AlzDf_test)

#CCDf
#only use the label biopsy
# drop the other labels
#CCDf2 <- subset(CCDf2, select= c(-))

#AuSDf
summary(AuSDf2)
head(AuSDf2)
#drop column X
AuSDf2<-subset(AuSDf2,select=c(- X))
colnames(AuSDf2)
AuSDf_shuff <- AuSDf2[sample(nrow(AuSDf2)),]
#split the data
inTrainAu <- createDataPartition(y=AuSDf_shuff$Class.ASD, p=0.75, list =FALSE)
AuSDf_train <- AuSDf_shuff[inTrainAu,]
AuSDf_test <- AuSDf_shuff[-inTrainAu,]
dim(AuSDf_test)
dim(AuSDf_train)

#LiverDf
colnames(LiverDf2)
head(LiverDf2)
#drop column X
LiverDf2<-subset(LiverDf2,select=c(- X))
colnames(LiverDf2)
LiverDf_shuff <- LiverDf2[sample(nrow(LiverDf2)),]
#split the data
inTrainLiver <- createDataPartition(y=LiverDf_shuff$Dataset, p=0.75, list =FALSE)
LiverDf_train <- LiverDf_shuff[inTrainLiver,]
LiverDf_test <- LiverDf_shuff[-inTrainLiver,]
dim(LiverDf_test)
dim(LiverDf_train)
#DiabetesDF
colnames(DiabetesDf2)
#drop column X
DiabetesDf2<-subset(DiabetesDf2,select=c(- X))
colnames(DiabetesDf2)
DiabetesDf_shuff <- DiabetesDf2[sample(nrow(DiabetesDf2)),]
#split the data
inTrainDiab <- createDataPartition(y=DiabetesDf_shuff$Outcome, p=0.75, list =FALSE)
DiabetesDf_train <- DiabetesDf_shuff[inTrainDiab,]
DiabetesDf_test <- DiabetesDf_shuff[-inTrainDiab,]
dim(DiabetesDf_test)
dim(DiabetesDf_train)
#HAPDf
colnames(HAPDf2)
#drop column X
HAPDf2<-subset(HAPDf2,select=c(- X))
colnames(HAPDf2)
HAPDf_shuff <- HAPDf2[sample(nrow(HAPDf2)),]
#split the data
inTrainHAPDf <- createDataPartition(y=HAPDf_shuff$num, p=0.75, list =FALSE)
HAPDf_train <-HAPDf_shuff[inTrainHAPDf,]
HAPDf_test <- HAPDf_shuff[-inTrainHAPDf,]
dim(HAPDf_test)
dim(HAPDf_train)

#LBPDF
colnames(LBPDf2)
#drop column X
LBPDf2<-subset(LBPDf2,select=c(- X, -X.1))
colnames(LBPDf2)
LBPDf_shuff <- LBPDf2[sample(nrow(LBPDf2)),]
#split the data
inTrainLBPDf <- createDataPartition(y=LBPDf_shuff$Class_label, p=0.75, list =FALSE)
LBPDf_train <-LBPDf_shuff[inTrainLBPDf,]
LBPDf_test <- LBPDf_shuff[-inTrainLBPDf,]
dim(LBPDf_test)
dim(LBPDf_train)

#FertDf
colnames(FertDf2)
#drop column X
FertDf2<-subset(FertDf2,select=c(- X))
colnames(FertDf2)
FertDf_shuff <- FertDf2[sample(nrow(FertDf2)),]
#split the data
inTrainFertDf <- createDataPartition(y=FertDf_shuff$Diagnosis, p=0.75, list =FALSE)
FertDf_train <-FertDf_shuff[inTrainFertDf,]
FertDf_test <- FertDf_shuff[-inTrainFertDf,]
dim(FertDf_test)
dim(FertDf_train)




```
```{r Random forest modelling}
library(randomForest)
library(ModelMetrics)

#BCDf2
#number of initial trees
ntrees<-500
#create a dataframe to store the accuracies and corresponding number of trees and other metrics
resultsBC <- data.frame(NTrees=as.numeric(), Accuracy=as.numeric(), F1=as.numeric(), Recall = as.numeric()) #
#fit randomForest 10 times and store the results 
#vary the number of trees in every iteration
colnames(BCDf_train)
colnames(BCDf_test)
BCDf_train$diagnosis <- as.factor(BCDf_train$diagnosis)
BCDf_test$diagnosis <- as.factor((BCDf_test$diagnosis))
for (i in 1:10){
  RFModelBC <-randomForest(BCDf_train[, -2],
                          BCDf_train[, 2], 
                          xtest=BCDf_test[, -2], 
                          ytest=BCDf_test[, 2], 
                          ntree = 1300,
                         proximity = TRUE
                        )
  #test the model for this run
  preds <- levels(BCDf_train[, 2])[RFModelBC$test$predicted] #
  actual <- levels(BCDf_train[, 2])[RFModelBC$test$err.rate]
  print(preds)
  print(actual)
  print(confusionMatrix(BCDf_test$diagnosis, RFModelBC$test$predicted,0.5))
  #compute accuracy
  accuRF <-(sum(preds==BCDf_test[, 2])/nrow(BCDf_test))*100
  #precision Precision = TP/TP+FP
  preciBC <- precision(BCDf_test$diagnosis, RFModelBC$test$predicted, 0.5)
  precBC <- sum()
  # Recall Recall = TP/TP+FN
  
  #F1 Score = 2*(Recall * Precision) / (Recall + Precision)
  F1BC <- (sum())
  #F1BC <-f1Score(BCDf_test$diagnosis, RFModelBC$test$predicted,0.5)
  recallBC <- recall(BCDf_test$diagnosis, RFModelBC$test$predicted, 0.5)
  resultsBC<- rbind(resultsBC, data.frame(NTrees=ntrees,Accuracy=accuRF, F1= F1BC, Recall = recallBC)) #, 
  ntrees <- ntrees + 100 
}#end for loop


resultsBC

#AlzDf2
#number of initial trees
ntrees<-500
resultsAlz <- data.frame(NTrees=as.numeric(), Accuracy=as.numeric(), AUC=as.numeric()) #, F1=as.numeric()
#fit randomForest 10 times and store the results 
#vary the number of trees in every iteration
colnames(AlzDf_train)
colnames(AlzDf_test)

#convert the class label as a factor
AlzDf_train$Group <- as.factor((AlzDf_train$Group))
AlzDf_test$Group <- as.factor((AlzDf_test$Group))
for (i in 1:10){
  RFModelAlz <-randomForest(AlzDf_train[, -1], #class label is column 3
                          AlzDf_train[, 1], 
                          xtest=AlzDf_test[, -1], 
                          ytest=AlzDf_test[, 1], 
                          ntree = ntrees,
                         proximity = TRUE
                        )
  #test the model for this run
  predsAlz <- levels(AlzDf_train[, 1])[RFModelAlz$test$predicted] #compute accuracy
  print(predsAlz)
  accuAlzRF <-(sum(predsAlz==AlzDf_test[, 1])/nrow(AlzDf_test))*100 
  #F1BC <-f1Score(BCDf_test$diagnosis, preds,0.5)
  resultsAlz<- rbind(resultsAlz, data.frame(NTrees=ntrees,Accuracy=accuAlzRF)) #, F1= F1BC
  ntrees <- ntrees + 100 
}#end for loop

resultsAlz

#CCDf2)
#remember to aggregate the score for this one

#AuSDf2
ntrees<-500
resultsAuS <- data.frame(NTrees=as.numeric(), Accuracy=as.numeric(), AUC=as.numeric()) #, F1=as.numeric()
#fit randomForest 10 times and store the results 
#vary the number of trees in every iteration
colnames(AuSDf_train)
colnames(AuSDf_test)

#convert the class label as a factor
AuSDf_train$Class.ASD <- as.factor((AuSDf_train$Class.ASD))
AuSDf_test$Class.ASD <- as.factor((AuSDf_test$Class.ASD))
levels(AuSDf_train$contry_of_res)
#there are 65 possible country of residence, RF only supports up to 53
#consider that country of residence may not have an impact on autism diagnostic and drop the column?
#drop the contry of residence in train and test
#or convert to string 
# returns an error (see unusued code at bottom of notebook)

AuSDf_train<-subset(AuSDf_train,select=c(- contry_of_res))
AuSDf_test<-subset(AuSDf_test,select=c(- contry_of_res))
for (i in 1:10){
  RFModelAuS <-randomForest(AuSDf_train[, -ncol(AuSDf_train)], #class label is last column
                          AuSDf_train[, ncol(AuSDf_train)], 
                          xtest=AuSDf_test[, -ncol(AuSDf_test)], 
                          ytest=AuSDf_test[, ncol(AuSDf_test)], 
                          ntree = ntrees,
                         proximity = TRUE
                        )
  #test the model for this run
  predsAuS <- levels(AuSDf_train[, ncol(AuSDf_train)])[RFModelAuS$test$predicted] #compute accuracy
  print(predsAuS)
  accuAuSRF <-(sum(predsAuS==AuSDf_test[, ncol(AuSDf_test)])/nrow(AuSDf_test))*100 
  #F1BC <-f1Score(BCDf_test$diagnosis, preds,0.5)
  resultsAuS<- rbind(resultsAuS, data.frame(NTrees=ntrees,Accuracy=accuAuSRF)) #, F1= F1BC
  ntrees <- ntrees + 100 
}#end for loop

resultsAuS
# 100 % accuracy is suspicious

#DiabetesDf2
ntrees<-500
resultsDiab <- data.frame(NTrees=as.numeric(), Accuracy=as.numeric(), AUC=as.numeric()) #, F1=as.numeric()
#fit randomForest 10 times and store the results 
#vary the number of trees in every iteration
colnames(DiabetesDf_train)
colnames(DiabetesDf_test)

#convert the class label as a factor
DiabetesDf_train$Outcome <- as.factor((DiabetesDf_train$Outcome))
DiabetesDf_test$Outcome <- as.factor((DiabetesDf_test$Outcome))

for (i in 1:10){
  RFModelDiab <-randomForest(DiabetesDf_train[, -ncol(DiabetesDf_train)], #class label is last column
                          DiabetesDf_train[, ncol(DiabetesDf_train)], 
                          xtest=DiabetesDf_test[, -ncol(DiabetesDf_test)], 
                          ytest=DiabetesDf_test[, ncol(DiabetesDf_test)], 
                          ntree = ntrees,
                         proximity = TRUE
                        )
  #test the model for this run
  predsDiab <- levels(DiabetesDf_train[, ncol(DiabetesDf_train)])[RFModelDiab$test$predicted] #compute accuracy
  print(predsDiab)
  accuDiabRF <-(sum(predsDiab==DiabetesDf_test[, ncol(DiabetesDf_test)])/nrow(DiabetesDf_test))*100 
  #F1BC <-f1Score(BCDf_test$diagnosis, preds,0.5)
  resultsDiab<- rbind(resultsDiab, data.frame(NTrees=ntrees,Accuracy=accuDiabRF)) #, F1= F1BC
  ntrees <- ntrees + 100 
}#end for loop

resultsDiab

#LiverDf2
ntrees<-500
resultsLiv <- data.frame(NTrees=as.numeric(), Accuracy=as.numeric(), AUC=as.numeric()) #, F1=as.numeric()
#fit randomForest 10 times and store the results 
#vary the number of trees in every iteration
colnames(LiverDf_train)
colnames(LiverDf_test)

#convert the class label as a factor
LiverDf_train$Dataset <- as.factor((LiverDf_train$Dataset))
LiverDf_test$Dataset <- as.factor((LiverDf_test$Dataset))

for (i in 1:10){
  RFModelLiver <-randomForest(LiverDf_train[, -ncol(LiverDf_train)], #class label is last column
                              LiverDf_train[, ncol(LiverDf_train)], 
                              xtest=LiverDf_test[, -ncol(LiverDf_test)], 
                              ytest=LiverDf_test[, ncol(LiverDf_test)], 
                              ntree = ntrees,
                              proximity = TRUE
                        )
  #test the model for this run
  predsLiv <- levels(LiverDf_train[, ncol(LiverDf_train)])[RFModelLiver$test$predicted] #compute accuracy
  print(predsLiv)
  accuLivRF <-(sum(predsLiv==LiverDf_test[, ncol(LiverDf_test)])/nrow(LiverDf_test))*100 
  #F1BC <-f1Score(BCDf_test$diagnosis, preds,0.5)
  resultsLiv<- rbind(resultsLiv, data.frame(NTrees=ntrees,Accuracy=accuLivRF)) #, F1= F1BC
  ntrees <- ntrees + 100 
}#end for loop

resultsLiv

#FertDf2
ntrees<-500
resultsFert <- data.frame(NTrees=as.numeric(), Accuracy=as.numeric(), AUC=as.numeric()) #, F1=as.numeric()
#fit randomForest 10 times and store the results 
#vary the number of trees in every iteration
colnames(FertDf_train)
colnames(FertDf_test)

#convert the class label as a factor
FertDf_train$Diagnosis <- as.factor((FertDf_train$Diagnosis))
FertDf_test$Diagnosis <- as.factor((FertDf_test$Diagnosis))

for (i in 1:10){
  RFModelFert <-randomForest(FertDf_train[, -ncol(FertDf_train)], #class label is last column
                             FertDf_train[, ncol(FertDf_train)], 
                             xtest=FertDf_test[, -ncol(FertDf_test)], 
                             ytest=FertDf_test[, ncol(FertDf_test)], 
                             ntree = ntrees,
                             proximity = TRUE
                        )
  #test the model for this run
  predsFert <- levels(FertDf_train[, ncol(FertDf_train)])[RFModelFert$test$predicted] #compute accuracy
  print(predsFert)
  accuFertRF <-(sum(predsFert==FertDf_test[, ncol(FertDf_test)])/nrow(FertDf_test))*100 
  #F1BC <-f1Score(BCDf_test$diagnosis, preds,0.5)
  resultsFert<- rbind(resultsFert, data.frame(NTrees=ntrees,Accuracy=accuFertRF)) #, F1= F1BC
  ntrees <- ntrees + 100 
}#end for loop

resultsFert


#HAPDf2
ntrees<-500
resultsHAP <- data.frame(NTrees=as.numeric(), Accuracy=as.numeric(), AUC=as.numeric()) #, F1=as.numeric()
#fit randomForest 10 times and store the results 
#vary the number of trees in every iteration
colnames(HAPDf_train)
colnames(HAPDf_test)
head(HAPDf_train)
levels(HAPDf_train$trestbps)
levels(HAPDf_train$chol) # too many factor categories in this column - convert to numeric
HAPDf_train$chol<- as.numeric(HAPDf_train$chol)
HAPDf_test$chol<- as.numeric(HAPDf_test$chol)
levels(HAPDf_train$fbs)
levels(HAPDf_train$restecg)
levels(HAPDf_train$thalach) #too many factor categories in this column - convert to numeric
HAPDf_train$thalach<- as.numeric(HAPDf_train$thalach)
HAPDf_test$thalach<- as.numeric(HAPDf_test$thalach)
levels(HAPDf_train$exang)
levels(HAPDf_train$slope)
levels(HAPDf_train$ca)
levels(HAPDf_train$thal)
#convert the class label as a factor
HAPDf_train$num <- as.factor((HAPDf_train$num))
HAPDf_test$num <- as.factor((HAPDf_test$num))

for (i in 1:10){
  RFModelHAP <-randomForest(HAPDf_train[, -ncol(HAPDf_train)], #class label is last column
                            HAPDf_train[, ncol(HAPDf_train)], 
                            xtest=HAPDf_test[, -ncol(HAPDf_test)], 
                            ytest=HAPDf_test[, ncol(HAPDf_test)], 
                            ntree = ntrees,
                            proximity = TRUE
                        )
  #test the model for this run
  predsHAP <- levels(HAPDf_train[, ncol(HAPDf_train)])[RFModelHAP$test$predicted] #compute accuracy
  print(predsHAP)
  accuHAPRF <-(sum(predsHAP==HAPDf_test[, ncol(HAPDf_test)])/nrow(HAPDf_test))*100 
  #F1BC <-f1Score(BCDf_test$diagnosis, preds,0.5)
  resultsHAP<- rbind(resultsHAP, data.frame(NTrees=ntrees,Accuracy=accuHAPRF)) #, F1= F1BC
  ntrees <- ntrees + 100 
}#end for loop

resultsHAP


#LBPDf2

ntrees<-500
resultsLBP <- data.frame(NTrees=as.numeric(), Accuracy=as.numeric(), AUC=as.numeric()) #, F1=as.numeric()
#fit randomForest 10 times and store the results 
#vary the number of trees in every iteration
colnames(LBPDf_train)
colnames(LBPDf_test)
head(LBPDf_train)

#convert the class label as a factor
LBPDf_train$Class_label <- as.factor((LBPDf_train$Class_label))
LBPDf_test$Class_label <- as.factor((LBPDf_test$Class_label))

for (i in 1:10){
  RFModelLBP <-randomForest(LBPDf_train[, -ncol(LBPDf_train)], #class label is last column
                            LBPDf_train[, ncol(LBPDf_train)], 
                            xtest=LBPDf_test[, -ncol(LBPDf_test)], 
                            ytest=LBPDf_test[, ncol(LBPDf_test)], 
                            ntree = ntrees,
                            proximity = TRUE
                        )
  #test the model for this run
  predsLBP <- levels(LBPDf_train[, ncol(LBPDf_train)])[RFModelLBP$test$predicted] #compute accuracy
  print(predsLBP)
  accuLBPRF <-(sum(predsLBP==LBPDf_test[, ncol(LBPDf_test)])/nrow(LBPDf_test))*100 
  #F1BC <-f1Score(BCDf_test$diagnosis, preds,0.5)
  resultsLBP<- rbind(resultsLBP, data.frame(NTrees=ntrees,Accuracy=accuLBPRF)) #, F1= F1BC
  ntrees <- ntrees + 100 
}#end for loop

resultsLBP


#randomForest(x, y=NULL,  xtest=NULL, ytest=NULL, ntree=500,proximity)

```
```{r export datasets as csv}

```

```{r unusued}
# AuSDf_train$contry_of_res <- as.character(AuSDf_train$contry_of_res)
# AuSDf_test$contry_of_res<- as.character(AuSDf_test$contry_of_res)
# head(AuSDf_train)
# str(AuSDf_train$contry_of_res)
# AuSDf_train$contry_of_res[AuSDf_train$contry_of_res == "'United Kingdom'"] <- "UK"
# AuSDf_train$contry_of_res[AuSDf_train$contry_of_res == "'United States'"] <- "US"
# AuSDf_train$contry_of_res[AuSDf_train$contry_of_res == "'New Zealand'"] <- "NZ"
# AuSDf_train$contry_of_res[AuSDf_train$contry_of_res == "'Sri Lanka'"] <- "Sri Lanka"
# AuSDf_train$contry_of_res[AuSDf_train$contry_of_res == "'United Arab Emirates'"] <- "UAE"
# AuSDf_train$contry_of_res[AuSDf_train$contry_of_res == "'Viet Nam'"] <- "Vietnam"
# AuSDf_train$contry_of_res[AuSDf_train$contry_of_res == "'Saudi Arabia'"] <- "Saudi Arabia"
# AuSDf_train$contry_of_res[AuSDf_train$contry_of_res == "'Sierra Leone'"] <- "Sierra Leone"
# print(AuSDf_train$contry_of_res)
# AuSDf_test$contry_of_res[AuSDf_test$contry_of_res == "'United Kingdom'"] <- "UK"
# AuSDf_test$contry_of_res[AuSDf_test$contry_of_res == "'United States'"] <- "US"
# AuSDf_test$contry_of_res[AuSDf_test$contry_of_res == "'New Zealand'"] <- "NZ"
# AuSDf_test$contry_of_res[AuSDf_test$contry_of_res == "'Sri Lanka'"] <- "Sri Lanka"
# AuSDf_test$contry_of_res[AuSDf_test$contry_of_res == "'United Arab Emirates'"] <- "UAE"
# AuSDf_test$contry_of_res[AuSDf_test$contry_of_res == "'Viet Nam'"] <- "Vietnam"
# AuSDf_test$contry_of_res[AuSDf_test$contry_of_res == "'Saudi Arabia'"] <- "Saudi Arabia"
# AuSDf_test$contry_of_res[AuSDf_test$contry_of_res == "'Sierra Leone'"] <- "Sierra Leone"
# print(AuSDf_test$contry_of_res)

#error returned by RF model for AuSDf when country is changed to character
#NAs introduced by coercionNAs introduced by coercionError in randomForest.default(AuSDf_train[, -ncol(AuSDf_train)], #AuSDf_train[,  : 
 # NA/NaN/Inf in foreign function call (arg 1)
```

